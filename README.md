# Consumer Sentiments and Ratings
#### _Зернышкина Екатерина_
## ***Cодержание проекта***
### Постановка задачи
С помощью LSTM надо определить, какую окраску носит отзыв пользователя (негативную, нейтральную или позитивную)
#### Формат входных и выходных данных
На вход модель будет получать комментарий пользователя. На выходе ожидается предсказание окраски комментария (негативный, нейтральный, позитивный).
#### Метрики
Я буду использовать accuracy. Ожидаю получить значения около 0.87, т.к. одним из пользователей kaggle с помощью lstm были получены такие значения https://www.kaggle.com/code/muhammedaliyilmazz/lstm-sentiment-analysis-with-0-87-accuracy/notebook.
#### Валидация
Для тестовой и тренировочной выборок буду брать данные так, чтобы в них сохранялся исходный баланс классов.
#### Данные
Датасет с Kaggle https://www.kaggle.com/datasets/kapturovalexander/consumer-sentiments-and-ratings/data.
Этот набор данных содержит отзывы покупателей о различных продуктах, включая подробную информацию о категориях продуктов, брендах, рейтингах пользователей и анализе настроений. Набор данных можно использовать для классификации настроений, создания систем рекомендаций и анализа поведения потребителей.
Использовать буду колонки - комментарий и тональность. Надо убрать пропуски, если есть, и предобработать текст комментариев, убрав пунктуацию, цифры и переведя слова в токены.
### Моделирование
#### Бейзлайн
На тренировочной выборке отобрать слова, которые чаще всего встречаются в позитивных/негативных комментариях. Каких слов в комментарии больше, к тому классу и относим. При равенстве количества позитивных и негативных слов или их отсутствии, комментарий считаем нейтральным. 
#### Основная модель
За основу возьму модель пользователя kaggle https://www.kaggle.com/code/muhammedaliyilmazz/lstm-sentiment-analysis-with-0-87-accuracy/notebook. Схема примерно следующая: эмбеддинги -> bidirectional lstm -> dropout -> lstm -> dropout -> lstm -> dense_layer с relu -> dropout -> dense_layer с softmax
Функция потерь - категориальная кросс-энтропия, оптимизатор - Adam. Для нейросети буду использовать tensorflow.
### Внедрение
После клонирования и установки необходимого для репозитория надо запустить обучение модели сохранением в формате .keras. Далее можно передавать свои данные и использовать модель по аналогии со скриптом infer.py.
## Технические детали
### Setup
# Клонируйте репозиторий 
git clone https://github.com/KateZernyshkina/sentiment-analysis.git
cd sentiment-analysis
# Создайте чистый virtualenv
python3 -m venv .venv
source .venv/bin/activate
# Установите poetry
pip install poetry
poetry install
# Установите pre-commit
pre-commit install
### Train
# Обучение модели запускается командой
poetry run python sentiment_analysis/train.py
# Запуск сервера 
mlflow server --host 0.0.0.0 --port 8080
При запуске обучения выполняется следующее. Данные скачиваются из открытого репозитория в скрипте sentiment_analysis/data.py и сохраняются в папку data. В скрипте sentiment_analysis/preprocess.py происходит предобработка данных. По результату тренировки модели получаем accuracy. Настроить параметры тренировки можно в configs/train.yaml. Должны появиться графики лосса и accuracy в папке plots. Создаются артефакты model.keras, label_encoder.pkl, tokenizer.pkl, которые можно использовать для предсказаний.
### Production preparation
# Для получения модели в формате onnx запустите скрипт ниже.
poetry run python sentiment_analysis/export.py
Для работы с моделью нужны артефакты model.keras, label_encoder.pkl, tokenizer.pkl и предобработка данных. Примеры применения модели можно посмотреть в скрипте infer.py и predict.py.
### Infer
Для предсказания модели нужна таблица в формате csv (далее преобразуется в датафрейм) с колонкой comment. Примеры применения модели можно посмотреть в скрипте infer.py (оценивает комментарий, введенный в консоли) и predict.py (оценивает комментарии в таблице).
# Для запуска в зависимости от вашей цели используйте:
poetry run python sentiment_analysis/infer.py    
или
poetry run python sentiment_analysis/predict.py
predict создаст матрицу ошибок (если в данных указан истинный ответ - tonality)
# Оценка сети и сравнение с базовой моделью
Графики и матрица ошибок показали, что модель выучилась всегда предсказывать позитивную тональность. Это связано с тем, что классы не сбалансированы. Accuracy получилась около 0.84. Для сравнения была сделана простая модель (sentiment_analysis/base_model.py). Для слов считается частота, с которой оно встречается в негативных и позитивных комментариях (для негативных комментариев - количество негативных текстов, в которых слово встретилось, делить на общее количество негативных текстов). Если в комментарии суммарная частота появления слов в негативных комментариях больше, то он негативный. Иначе позитивный. Такая модель работает достаточно хорошо - accuracy 0.82. Дисбаланс классов не так сильно повлиял на простую модель. Матрица ошибок этой модели (в папке plots) выглядит более разумной, чем матрица нейросети.

